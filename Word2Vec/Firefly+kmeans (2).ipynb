{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49aa666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903ed816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb2e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute inertia and assign labels to closest centroid\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "\n",
    "def compute_inertia(centroids, data, threshold=100000, distance_metric='manhattan'):\n",
    "    # Choose distance metric\n",
    "    if distance_metric == 'euclidean':\n",
    "        distances = euclidean_distances(data, centroids)\n",
    "    elif distance_metric == 'manhattan':\n",
    "        distances = manhattan_distances(data, centroids)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric. Choose 'euclidean' or 'manhattan'.\")\n",
    "\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    # Assign -1 for distances greater than threshold\n",
    "    labels[min_distances > threshold] = -1\n",
    "\n",
    "    # Compute inertia for assigned data points\n",
    "    assigned_data_points = data[labels != -1]\n",
    "    if len(assigned_data_points) > 0:\n",
    "        assigned_labels = labels[labels != -1]\n",
    "        inertia = np.sum((assigned_data_points - centroids[assigned_labels]) ** 2)\n",
    "    else:\n",
    "        inertia = 0\n",
    "\n",
    "    # Calculate additional metrics if needed\n",
    "    num_outliers = np.sum(labels == -1)\n",
    "    average_distance = np.mean(min_distances[labels != -1]) if len(assigned_data_points) > 0 else 0\n",
    "\n",
    "    return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e843dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firefly:\n",
    "    def __init__(self, data, n_clusters):\n",
    "        self.position = data[np.random.choice(data.shape[0], n_clusters, replace=False), :]\n",
    "        self.fitness = compute_inertia(self.position, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11cdefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firefly_kmeans(data, n_clusters, n_fireflies=10, max_iter=100, alpha=0.5, gamma=1.0):\n",
    "    fireflies = [Firefly(data, n_clusters) for _ in range(n_fireflies)]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        fireflies.sort(key=lambda x: x.fitness)\n",
    "        for i in range(n_fireflies):\n",
    "            for j in range(n_fireflies):\n",
    "                if fireflies[j].fitness < fireflies[i].fitness:  # Move i towards j\n",
    "                    r = np.linalg.norm(fireflies[i].position - fireflies[j].position)\n",
    "                    beta0 = 1\n",
    "                    beta = beta0 * np.exp(-gamma * r**2)\n",
    "                    fireflies[i].position += beta * (fireflies[j].position - fireflies[i].position) + alpha * (np.random.rand(*fireflies[i].position.shape) - 0.5)\n",
    "                    fireflies[i].fitness = compute_inertia(fireflies[i].position, data)\n",
    "\n",
    "    best_firefly = fireflies[0]\n",
    "    final_kmeans = KMeans(n_clusters=n_clusters, init=np.array(best_firefly.position), n_init=1, max_iter=300)\n",
    "    final_kmeans.fit(data)\n",
    "    return final_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831d923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d15d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Devendra\n",
      "[nltk_data]     Nemade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Devendra\n",
      "[nltk_data]     Nemade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize stopwords, stemmer, and punctuation set\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation_set = set(string.punctuation)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8d61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convert to lowercase, remove punctuation, remove stopwords, and stem\n",
    "    processed_tokens = [stemmer.stem(word.lower()) for word in tokens if word.lower() not in stop_words and word not in punctuation_set]\n",
    "    # Re-join processed tokens into a single string\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081a82c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing the text data...\n",
      "Loading Word2Vec model...\n",
      "Obtaining Word2Vec embeddings for each document...\n"
     ]
    }
   ],
   "source": [
    "processed_data = [preprocess_text(doc) for doc in newsgroups_dataset.data]\n",
    "# Use TfidfVectorizer to convert the raw text into TF-IDF features\n",
    "print(\"Vectorizing the text data...\")\n",
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "# Load Word2Vec model trained on Google News dataset\n",
    "print(\"Loading Word2Vec model...\")\n",
    "word2vec_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Define a function to get the vector representation of a document\n",
    "def document_vector(doc):\n",
    "    # Remove punctuation and tokenize the document\n",
    "    tokens = [word.lower() for word in word_tokenize(doc) if word.lower() not in punctuation_set]\n",
    "    # Filter out tokens that are not in the Word2Vec model's vocabulary\n",
    "    tokens = [word for word in tokens if word in word2vec_model.key_to_index]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    # Calculate the mean of word vectors for tokens in the document\n",
    "    return np.mean(word2vec_model[tokens], axis=0)\n",
    "\n",
    "# Obtain Word2Vec embeddings for each document\n",
    "print(\"Obtaining Word2Vec embeddings for each document...\")\n",
    "word2vec_embeddings = np.array([document_vector(doc) for doc in processed_data])\n",
    "n_components = 100\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "tfidf_matrix_reduced = svd.fit_transform(word2vec_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb99faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "befc0414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers: [[ 7.48137066e-01 -1.01397252e-01 -8.03535080e-02 ... -1.37926776e-03\n",
      "  -2.91331663e-03  1.85280105e-03]\n",
      " [ 7.68187778e-01  1.42020798e-01 -2.51274254e-01 ...  1.45760558e-03\n",
      "  -5.18606089e-04 -5.11972286e-04]\n",
      " [ 7.63019607e-01 -1.19693480e-01  9.67469290e-02 ...  2.79883823e-03\n",
      "   2.92514697e-03  2.22010558e-03]\n",
      " ...\n",
      " [ 8.08995502e-01 -1.03511840e-01 -3.15730925e-02 ... -1.13072955e-03\n",
      "  -1.67079916e-05 -1.25393916e-03]\n",
      " [ 8.59194332e-01  3.03169800e-02  1.33908126e-01 ... -1.95825012e-03\n",
      "   1.36219289e-04  1.94808343e-03]\n",
      " [ 8.18640129e-01  1.66322391e-02  2.52665707e-01 ...  3.78496752e-04\n",
      "  -3.93213646e-03 -2.38146909e-03]]\n",
      "Labels: [ 3 12 15 ...  1  2 14]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 20\n",
    "kmeans = firefly_kmeans(tfidf_matrix_reduced, n_clusters)\n",
    "print(\"Cluster centers:\", kmeans.cluster_centers_)\n",
    "print(\"Labels:\", kmeans.labels_)\n",
    "#Firefly-Kmeans on 20newsgroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa7b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers: [[ 7.48137066e-01 -1.01397252e-01 -8.03535080e-02 ... -1.37926776e-03\n",
      "  -2.91331663e-03  1.85280105e-03]\n",
      " [ 7.68187778e-01  1.42020798e-01 -2.51274254e-01 ...  1.45760558e-03\n",
      "  -5.18606089e-04 -5.11972286e-04]\n",
      " [ 7.63019607e-01 -1.19693480e-01  9.67469290e-02 ...  2.79883823e-03\n",
      "   2.92514697e-03  2.22010558e-03]\n",
      " ...\n",
      " [ 8.08995502e-01 -1.03511840e-01 -3.15730925e-02 ... -1.13072955e-03\n",
      "  -1.67079916e-05 -1.25393916e-03]\n",
      " [ 8.59194332e-01  3.03169800e-02  1.33908126e-01 ... -1.95825012e-03\n",
      "   1.36219289e-04  1.94808343e-03]\n",
      " [ 8.18640129e-01  1.66322391e-02  2.52665707e-01 ...  3.78496752e-04\n",
      "  -3.93213646e-03 -2.38146909e-03]]\n",
      "Labels: [ 3 12 15 ...  1  2 14]\n",
      "Silhouette Score: 0.03811588021246144\n",
      "Davies-Bouldin Index: 2.7280705464101653\n",
      "Calinski-Harabasz Index: 380.81844351933836\n"
     ]
    }
   ],
   "source": [
    "silhouette = silhouette_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "davies_bouldin = davies_bouldin_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "calinski_harabasz = calinski_harabasz_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "\n",
    "print(\"Cluster centers:\", kmeans.cluster_centers_)\n",
    "print(\"Labels:\", kmeans.labels_)\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475f71cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "calinski_harabasz_scores = []\n",
    "Labels_save=[];\n",
    "for n_clusters in range(2, 21):\n",
    "    # Run PSO-KMeans with the current number of clusters\n",
    "    kmeans =  firefly_kmeans(tfidf_matrix_reduced, n_clusters)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    silhouette = silhouette_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "    davies_bouldin = davies_bouldin_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "    calinski_harabasz = calinski_harabasz_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "    \n",
    "    # Store metrics\n",
    "    silhouette_scores.append(silhouette)\n",
    "    davies_bouldin_scores.append(davies_bouldin)\n",
    "    calinski_harabasz_scores.append(calinski_harabasz)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd803c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2870759568.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    Silhouette Score\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting the metrics\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "Silhouette Score\n",
    "axs[0].plot(range(2, 21), silhouette_scores, marker='o', linestyle='-', color='blue')\n",
    "axs[0].set_title('Silhouette Score')\n",
    "axs[0].set_xlabel('Number of Clusters')\n",
    "axs[0].set_ylabel('Silhouette Score')\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "axs[1].plot(range(2, 21), davies_bouldin_scores, marker='o', linestyle='-', color='red')\n",
    "axs[1].set_title('Davies-Bouldin Score')\n",
    "axs[1].set_xlabel('Number of Clusters')\n",
    "axs[1].set_ylabel('Davies-Bouldin Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Davies-Bouldin Score_News_word2vec_firefly-Kmeans.png\")\n",
    "# Calinski-Harabasz Score\n",
    "axs[2].plot(range(2, 21), calinski_harabasz_scores, marker='o', linestyle='-', color='green')\n",
    "axs[2].set_title('Calinski-Harabasz Score')\n",
    "axs[2].set_xlabel('Number of Clusters')\n",
    "axs[2].set_ylabel('Calinski-Harabasz Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Calinski-Harabasz Score_News_word2vec_firefly-Kmeans.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "773af273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>davies_bouldin_scores</th>\n",
       "      <th>calinski_harabasz_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102690</td>\n",
       "      <td>3.469627</td>\n",
       "      <td>1140.288308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058308</td>\n",
       "      <td>3.278812</td>\n",
       "      <td>1011.011282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089144</td>\n",
       "      <td>2.571697</td>\n",
       "      <td>1015.983662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.072582</td>\n",
       "      <td>2.791839</td>\n",
       "      <td>915.089955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.064052</td>\n",
       "      <td>2.958459</td>\n",
       "      <td>811.491039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.061607</td>\n",
       "      <td>2.653671</td>\n",
       "      <td>735.711188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.057261</td>\n",
       "      <td>2.916292</td>\n",
       "      <td>681.697051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.060824</td>\n",
       "      <td>2.798546</td>\n",
       "      <td>636.332599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.063984</td>\n",
       "      <td>2.769854</td>\n",
       "      <td>600.554840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.049412</td>\n",
       "      <td>2.909121</td>\n",
       "      <td>566.461097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.054978</td>\n",
       "      <td>2.978087</td>\n",
       "      <td>531.390346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.044732</td>\n",
       "      <td>2.844466</td>\n",
       "      <td>506.031263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.050707</td>\n",
       "      <td>2.784850</td>\n",
       "      <td>488.430708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.047566</td>\n",
       "      <td>2.775784</td>\n",
       "      <td>461.134211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.042127</td>\n",
       "      <td>2.829520</td>\n",
       "      <td>442.931913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.049266</td>\n",
       "      <td>2.774729</td>\n",
       "      <td>435.954994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.034472</td>\n",
       "      <td>2.982862</td>\n",
       "      <td>408.059222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.040826</td>\n",
       "      <td>2.678683</td>\n",
       "      <td>383.399062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.039617</td>\n",
       "      <td>2.706704</td>\n",
       "      <td>376.383912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Silhouette Score  davies_bouldin_scores  calinski_harabasz_scores\n",
       "2           0.102690               3.469627               1140.288308\n",
       "3           0.058308               3.278812               1011.011282\n",
       "4           0.089144               2.571697               1015.983662\n",
       "5           0.072582               2.791839                915.089955\n",
       "6           0.064052               2.958459                811.491039\n",
       "7           0.061607               2.653671                735.711188\n",
       "8           0.057261               2.916292                681.697051\n",
       "9           0.060824               2.798546                636.332599\n",
       "10          0.063984               2.769854                600.554840\n",
       "11          0.049412               2.909121                566.461097\n",
       "12          0.054978               2.978087                531.390346\n",
       "13          0.044732               2.844466                506.031263\n",
       "14          0.050707               2.784850                488.430708\n",
       "15          0.047566               2.775784                461.134211\n",
       "16          0.042127               2.829520                442.931913\n",
       "17          0.049266               2.774729                435.954994\n",
       "18          0.034472               2.982862                408.059222\n",
       "19          0.040826               2.678683                383.399062\n",
       "20          0.039617               2.706704                376.383912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'Silhouette Score':silhouette_scores,'davies_bouldin_scores': davies_bouldin_scores,\n",
    "        'calinski_harabasz_scores': calinski_harabasz_scores}\n",
    "df=pd.DataFrame(data,index=range(2, 21))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb70ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('News_word2vec_FIREFLY-Kmeans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823dcadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
