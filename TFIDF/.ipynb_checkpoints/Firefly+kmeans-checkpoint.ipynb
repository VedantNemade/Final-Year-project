{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49aa666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903ed816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb2e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute inertia and assign labels to closest centroid\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "\n",
    "def compute_inertia(centroids, data, threshold=100000, distance_metric='euclidean'):\n",
    "    # Choose distance metric\n",
    "    if distance_metric == 'euclidean':\n",
    "        distances = euclidean_distances(data, centroids)\n",
    "    elif distance_metric == 'manhattan':\n",
    "        distances = manhattan_distances(data, centroids)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric. Choose 'euclidean' or 'manhattan'.\")\n",
    "\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    # Assign -1 for distances greater than threshold\n",
    "    labels[min_distances > threshold] = -1\n",
    "\n",
    "    # Compute inertia for assigned data points\n",
    "    assigned_data_points = data[labels != -1]\n",
    "    if len(assigned_data_points) > 0:\n",
    "        assigned_labels = labels[labels != -1]\n",
    "        inertia = np.sum((assigned_data_points - centroids[assigned_labels]) ** 2)\n",
    "    else:\n",
    "        inertia = 0\n",
    "\n",
    "    # Calculate additional metrics if needed\n",
    "    num_outliers = np.sum(labels == -1)\n",
    "    average_distance = np.mean(min_distances[labels != -1]) if len(assigned_data_points) > 0 else 0\n",
    "\n",
    "    return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e843dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firefly:\n",
    "    def __init__(self, data, n_clusters):\n",
    "        self.position = data[np.random.choice(data.shape[0], n_clusters, replace=False), :]\n",
    "        self.fitness = compute_inertia(self.position, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11cdefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firefly_kmeans(data, n_clusters, n_fireflies=10, max_iter=100, alpha=0.5, gamma=1.0):\n",
    "    fireflies = [Firefly(data, n_clusters) for _ in range(n_fireflies)]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        fireflies.sort(key=lambda x: x.fitness)\n",
    "        for i in range(n_fireflies):\n",
    "            for j in range(n_fireflies):\n",
    "                if fireflies[j].fitness < fireflies[i].fitness:  # Move i towards j\n",
    "                    r = np.linalg.norm(fireflies[i].position - fireflies[j].position)\n",
    "                    beta0 = 1\n",
    "                    beta = beta0 * np.exp(-gamma * r**2)\n",
    "                    fireflies[i].position += beta * (fireflies[j].position - fireflies[i].position) + alpha * (np.random.rand(*fireflies[i].position.shape) - 0.5)\n",
    "                    fireflies[i].fitness = compute_inertia(fireflies[i].position, data)\n",
    "\n",
    "    best_firefly = fireflies[0]\n",
    "    final_kmeans = KMeans(n_clusters=n_clusters, init=np.array(best_firefly.position), n_init=1, max_iter=300)\n",
    "    final_kmeans.fit(data)\n",
    "    return final_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831d923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d15d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Devendra\n",
      "[nltk_data]     Nemade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Devendra\n",
      "[nltk_data]     Nemade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize stopwords, stemmer, and punctuation set\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation_set = set(string.punctuation)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8d61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convert to lowercase, remove punctuation, remove stopwords, and stem\n",
    "    processed_tokens = [stemmer.stem(word.lower()) for word in tokens if word.lower() not in stop_words and word not in punctuation_set]\n",
    "    # Re-join processed tokens into a single string\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "081a82c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing the text data...\n"
     ]
    }
   ],
   "source": [
    "processed_data = [preprocess_text(doc) for doc in newsgroups_dataset.data]\n",
    "# Use TfidfVectorizer to convert the raw text into TF-IDF features\n",
    "print(\"Vectorizing the text data...\")\n",
    "tfidf_vectorizer = CountVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_data)\n",
    "n_components = 100\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "tfidf_matrix_reduced = svd.fit_transform(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb99faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tfidf_matrix_reduced.dtype == 'float64':\n",
    "    tfidf_matrix_reduced = tfidf_matrix_reduced.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "befc0414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers: [[ 3.1455040e-02  1.9598429e+01  1.7179318e-02 ... -1.4953191e+00\n",
      "   7.7392226e-01  1.6810876e+00]\n",
      " [ 7.4753761e-03  1.8723436e+01 -1.5537143e-01 ...  6.0645634e-01\n",
      "   2.4249852e-01 -3.2502455e-01]\n",
      " [ 5.1758051e-02  4.8454414e+01  1.1990869e+00 ... -3.0532399e-01\n",
      "  -1.8798107e-01 -1.3856543e-02]\n",
      " ...\n",
      " [ 1.7081189e-01  3.1408291e+01  9.7976303e+00 ... -8.2656127e-01\n",
      "  -4.3289590e-01 -3.7248239e-01]\n",
      " [ 6.1805248e-03  9.5795155e+00  1.1733319e-01 ...  6.2279236e-01\n",
      "   3.0755270e-02 -2.3117356e-01]\n",
      " [ 2.7606916e-01  6.2049031e+00  3.3760271e+00 ... -3.0970180e-01\n",
      "  -2.7859988e+00 -6.9214541e-01]]\n",
      "Labels: [4 4 4 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 20\n",
    "kmeans = firefly_kmeans(tfidf_matrix_reduced, n_clusters)\n",
    "print(\"Cluster centers:\", kmeans.cluster_centers_)\n",
    "print(\"Labels:\", kmeans.labels_)\n",
    "#Firefly-Kmeans on 20newsgroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa7b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.6669077277183533\n",
      "Davies-Bouldin Index: 1.8149073041241923\n",
      "Calinski-Harabasz Index: 47745.25988670855\n"
     ]
    }
   ],
   "source": [
    "silhouette = silhouette_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "davies_bouldin = davies_bouldin_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "calinski_harabasz = calinski_harabasz_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f71cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99854606\n",
      "0.96139103\n",
      "0.95376194\n",
      "0.9585693\n",
      "0.9028944\n",
      "0.89169836\n",
      "0.77248585\n",
      "0.8918965\n",
      "0.7740748\n",
      "0.7707262\n",
      "0.6893455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "calinski_harabasz_scores = []\n",
    "Labels_save=[];\n",
    "for n_clusters in range(2, 21):\n",
    "    # Run PSO-KMeans with the current number of clusters\n",
    "    kmeans =  firefly_kmeans(tfidf_matrix_reduced, n_clusters)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    silhouette = silhouette_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "    print(silhouette)\n",
    "    davies_bouldin = davies_bouldin_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "    calinski_harabasz = calinski_harabasz_score(tfidf_matrix_reduced, kmeans.labels_)\n",
    "    \n",
    "    # Store metrics\n",
    "    silhouette_scores.append(silhouette)\n",
    "    davies_bouldin_scores.append(davies_bouldin)\n",
    "    calinski_harabasz_scores.append(calinski_harabasz)\n",
    "#     pca = PCA(n_components=2)\n",
    "#     pca_data = pca.fit_transform(tfidf_matrix_reduced)\n",
    "\n",
    "# # Visualizing the clusters\n",
    "#     plt.scatter(pca_data[:, 0], pca_data[:, 1], c=kmeans.labels_)\n",
    "#     plt.title(f'PCA of KMeans Clusters ({n_clusters} Clusters)')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd803c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting the metrics\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 15))\n",
    "\n",
    "# Silhouette Score\n",
    "axs[0].plot(range(2, 21), silhouette_scores, marker='o', linestyle='-', color='blue')\n",
    "axs[0].set_title('Silhouette Score')\n",
    "axs[0].set_xlabel('Number of Clusters')\n",
    "axs[0].set_ylabel('Silhouette Score')\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "axs[1].plot(range(2, 21), davies_bouldin_scores, marker='o', linestyle='-', color='red')\n",
    "axs[1].set_title('Davies-Bouldin Score')\n",
    "axs[1].set_xlabel('Number of Clusters')\n",
    "axs[1].set_ylabel('Davies-Bouldin Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Davies-Bouldin Score_News_count_firefly-Kmeans.png\")\n",
    "# Calinski-Harabasz Score\n",
    "axs[2].plot(range(2, 21), calinski_harabasz_scores, marker='o', linestyle='-', color='green')\n",
    "axs[2].set_title('Calinski-Harabasz Score')\n",
    "axs[2].set_xlabel('Number of Clusters')\n",
    "axs[2].set_ylabel('Calinski-Harabasz Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Calinski-Harabasz Score_News_count_firefly-Kmeans.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773af273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Silhouette Score':silhouette_scores,'davies_bouldin_scores': davies_bouldin_scores,\n",
    "        'calinski_harabasz_scores': calinski_harabasz_scores}\n",
    "df=pd.DataFrame(data,index=range(2, 21))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afb70ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('News_count_FIREFLY-Kmeans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823dcadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
