{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fcd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Compute inertia and assign labels to closest centroid\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f20c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "\n",
    "def compute_inertia(centroids, data, threshold=100000, distance_metric='manhattan'):\n",
    "    # Ensure centroids is a 2D array: if it's 1D, reshape it to 2D (1, number of features)\n",
    "    if centroids.ndim == 1:\n",
    "        centroids = centroids.reshape(1, -1)\n",
    "    \n",
    "    # Choose distance metric\n",
    "    if distance_metric == 'euclidean':\n",
    "        distances = euclidean_distances(data, centroids)\n",
    "    elif distance_metric == 'manhattan':\n",
    "        distances = manhattan_distances(data, centroids)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric. Choose 'euclidean' or 'manhattan'.\")\n",
    "\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    # Assign -1 for distances greater than threshold\n",
    "    labels[min_distances > threshold] = -1\n",
    "\n",
    "    # Compute inertia for assigned data points\n",
    "    assigned_data_points = data[labels != -1]\n",
    "    if len(assigned_data_points) > 0:\n",
    "        assigned_labels = labels[labels != -1]\n",
    "        inertia = np.sum((assigned_data_points - centroids[assigned_labels]) ** 2)\n",
    "    else:\n",
    "        inertia = 0\n",
    "\n",
    "    return inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74086097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devendra Nemade\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Devendra Nemade\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.27137297 0.29232688].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Example data\u001b[39;00m\n\u001b[0;32m     97\u001b[0m n_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 98\u001b[0m centroids, labels, inertia \u001b[38;5;241m=\u001b[39m firefly_cuckoo_kmeans(data, n_clusters)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentroids:\u001b[39m\u001b[38;5;124m\"\u001b[39m, centroids)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, labels)\n",
      "Cell \u001b[1;32mIn[12], line 89\u001b[0m, in \u001b[0;36mfirefly_cuckoo_kmeans\u001b[1;34m(data, n_clusters, max_iter)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m     88\u001b[0m     centroids \u001b[38;5;241m=\u001b[39m firefly_algorithm_update(centroids, data)\n\u001b[1;32m---> 89\u001b[0m     centroids \u001b[38;5;241m=\u001b[39m cuckoo_search_update(centroids, data)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# Optionally, you can intersperse KMeans steps to refine centroids\u001b[39;00m\n\u001b[0;32m     92\u001b[0m inertia, labels \u001b[38;5;241m=\u001b[39m compute_inertia_and_labels(centroids, data)\n",
      "Cell \u001b[1;32mIn[12], line 52\u001b[0m, in \u001b[0;36mcuckoo_search_update\u001b[1;34m(centroids, data, n_nests, pa)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuckoo_search_update\u001b[39m(centroids, data, n_nests\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pa\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m):\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simplified Cuckoo Search algorithm to update centroids.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     cuckoos \u001b[38;5;241m=\u001b[39m [Cuckoo(centroid, data) \u001b[38;5;28;01mfor\u001b[39;00m centroid \u001b[38;5;129;01min\u001b[39;00m centroids]\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_nests):\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cuckoo \u001b[38;5;129;01min\u001b[39;00m cuckoos:\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;66;03m# Generate new solution (new position for centroids)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuckoo_search_update\u001b[39m(centroids, data, n_nests\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pa\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m):\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simplified Cuckoo Search algorithm to update centroids.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     cuckoos \u001b[38;5;241m=\u001b[39m [Cuckoo(centroid, data) \u001b[38;5;28;01mfor\u001b[39;00m centroid \u001b[38;5;129;01min\u001b[39;00m centroids]\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_nests):\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cuckoo \u001b[38;5;129;01min\u001b[39;00m cuckoos:\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;66;03m# Generate new solution (new position for centroids)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36mCuckoo.__init__\u001b[1;34m(self, position, data)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, position, data):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m=\u001b[39m position\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m=\u001b[39m compute_inertia_and_labels(position, data)\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36mcompute_inertia_and_labels\u001b[1;34m(centroids, data)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_inertia_and_labels\u001b[39m(centroids, data):\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute inertia and assign labels to closest centroid.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     distances \u001b[38;5;241m=\u001b[39m euclidean_distances(data, centroids)\n\u001b[0;32m     26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(distances, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m     min_distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(distances, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:310\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_distances\u001b[39m(\n\u001b[0;32m    235\u001b[0m     X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, Y_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, X_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m ):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m           [1.41421356]])\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X_norm_squared \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m         X_norm_squared \u001b[38;5;241m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:173\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    166\u001b[0m         X,\n\u001b[0;32m    167\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    174\u001b[0m         Y,\n\u001b[0;32m    175\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    176\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    177\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    178\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    179\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.27137297 0.29232688].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "def initialize_centroids_with_kmeans(data, n_clusters):\n",
    "    \"\"\"Initialize centroids using KMeans.\"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(data)\n",
    "    return kmeans.cluster_centers_\n",
    "class Firefly:\n",
    "    def __init__(self, position):\n",
    "        self.position = position\n",
    "        self.fitness = float('inf')\n",
    "class Cuckoo:\n",
    "    def __init__(self, position, data):\n",
    "        self.position = position\n",
    "        self.fitness= compute_inertia_and_labels(position, data)\n",
    "\n",
    "def firefly_algorithm_update(centroids, data, n_fireflies=10, alpha=0.5, gamma=1.0):\n",
    "    \"\"\"Simplified Firefly algorithm to update centroids.\"\"\"\n",
    "    # Initialize fireflies based on the current centroids\n",
    "    if len(centroids) < n_fireflies:\n",
    "        # If there are fewer centroids than fireflies, replicate centroids\n",
    "        additional_fireflies = n_fireflies - len(centroids)\n",
    "        extra_centroids = np.tile(centroids, (additional_fireflies, 1))\n",
    "        fireflies = [Firefly(centroid) for centroid in np.vstack((centroids, extra_centroids))[:n_fireflies]]\n",
    "    else:\n",
    "        fireflies = [Firefly(centroid) for centroid in centroids[:n_fireflies]]\n",
    "    \n",
    "    # Evaluate initial fitness\n",
    "    for firefly in fireflies:\n",
    "        firefly.fitness = compute_inertia(firefly.position, data)\n",
    "    \n",
    "    # Firefly algorithm optimization loop\n",
    "    for i in range(n_fireflies):\n",
    "        for j in range(n_fireflies):\n",
    "            if fireflies[j].fitness < fireflies[i].fitness:  # Move i towards j\n",
    "                r = np.linalg.norm(fireflies[i].position - fireflies[j].position)\n",
    "                beta0 = 1\n",
    "                beta = beta0 * np.exp(-gamma * r**2)\n",
    "                fireflies[i].position += beta * (fireflies[j].position - fireflies[i].position) + alpha * (np.random.rand(*fireflies[i].position.shape) - 0.5)\n",
    "                fireflies[i].fitness = compute_inertia(fireflies[i].position, data)\n",
    "    \n",
    "    # Update centroids based on the best fireflies\n",
    "    updated_centroids = np.array([firefly.position for firefly in fireflies])\n",
    "    \n",
    "    return updated_centroids\n",
    "\n",
    "\n",
    "def cuckoo_search_update(centroids, data, n_nests=10, pa=0.25):\n",
    "    \"\"\"Simplified Cuckoo Search algorithm to update centroids.\"\"\"\n",
    "    cuckoos = [Cuckoo(centroid, data) for centroid in centroids]\n",
    "    \n",
    "    for _ in range(n_nests):\n",
    "        for cuckoo in cuckoos:\n",
    "            # Generate new solution (new position for centroids)\n",
    "            new_position = cuckoo.position + np.random.uniform(-1, 1, cuckoo.position.shape)\n",
    "            new_fitness, _ = compute_inertia_and_labels(new_position, data)\n",
    "\n",
    "            # Randomly choose another cuckoo (nest)\n",
    "            random_cuckoo = np.random.choice(cuckoos)\n",
    "\n",
    "            # Replace the position of the randomly chosen cuckoo if the new solution is better (has lower inertia)\n",
    "            if new_fitness < random_cuckoo.fitness:\n",
    "                random_cuckoo.position = new_position\n",
    "                random_cuckoo.fitness = new_fitness\n",
    "\n",
    "    # After iterating, select the best solutions\n",
    "    cuckoos.sort(key=lambda x: x.fitness)\n",
    "    \n",
    "    # Replace a fraction of the worst nests with new random solutions\n",
    "    for i in range(int(len(cuckoos) * pa), len(cuckoos)):\n",
    "        new_position = np.random.rand(*centroids.shape)  # Generate completely new solutions\n",
    "        cuckoos[i] = Cuckoo(new_position, data)\n",
    "\n",
    "    # Extract updated centroids from cuckoos\n",
    "    updated_centroids = np.array([cuckoo.position for cuckoo in cuckoos])\n",
    "    \n",
    "    return updated_centroids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def firefly_cuckoo_kmeans(data, n_clusters, max_iter=100):\n",
    "    \"\"\"Hybrid Firefly-Cuckoo-KMeans algorithm.\"\"\"\n",
    "    centroids = initialize_centroids_with_kmeans(data, n_clusters)\n",
    "    for iteration in range(max_iter):\n",
    "        centroids = firefly_algorithm_update(centroids, data)\n",
    "        centroids = cuckoo_search_update(centroids, data)\n",
    "        # Optionally, you can intersperse KMeans steps to refine centroids\n",
    "        \n",
    "    inertia, labels = compute_inertia_and_labels(centroids, data)\n",
    "    return centroids, labels, inertia\n",
    "\n",
    "# Example usage\n",
    "data = np.random.rand(100, 2)  # Example data\n",
    "n_clusters = 3\n",
    "centroids, labels, inertia = firefly_cuckoo_kmeans(data, n_clusters)\n",
    "print(\"Centroids:\", centroids)\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Inertia:\", inertia)\n",
    "\n",
    "\n",
    "silhouette = silhouette_score(data, labels)\n",
    "davies_bouldin = davies_bouldin_score(data, labels)\n",
    "calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05231ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
